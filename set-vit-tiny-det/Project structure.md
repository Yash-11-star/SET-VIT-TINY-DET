# Project Structure & File Organization

This document describes the complete file structure of the Vision Transformer Tiny Object Detection project.

## ğŸ“ Complete Directory Tree

```
set-vit-tiny-det/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                      # License file
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ Makefile                     # Build/development commands
â”‚
â”œâ”€â”€ ğŸ“ configs/                     # Configuration files
â”‚   â”œâ”€â”€ default.yaml               # Default model & training config
â”‚   â””â”€â”€ coco_small.yaml            # COCO small config (template)
â”‚
â”œâ”€â”€ ğŸ“ data/                        # Data directory
â”‚   â”œâ”€â”€ README_DATA.md             # Data format and preparation guide
â”‚   â”œâ”€â”€ train/                     # Training images (create this)
â”‚   â”œâ”€â”€ train_annotations.txt      # Training annotations
â”‚   â”œâ”€â”€ val/                       # Validation images (create this)
â”‚   â”œâ”€â”€ val_annotations.txt        # Validation annotations
â”‚   â”œâ”€â”€ test/                      # Test images (create this)
â”‚   â””â”€â”€ test_annotations.txt       # Test annotations
â”‚
â”œâ”€â”€ ğŸ“ scripts/                     # Shell scripts
â”‚   â”œâ”€â”€ setup_coco.sh              # Project setup script
â”‚   â”œâ”€â”€ train.sh                   # Training script
â”‚   â””â”€â”€ eval.sh                    # Evaluation script
â”‚
â”œâ”€â”€ ğŸ“ src/                         # Source code
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ datasets/               # Dataset module
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Module initialization
â”‚   â”‚   â”œâ”€â”€ coco.py               # TinyObjectDataset class
â”‚   â”‚   â””â”€â”€ transforms.py         # Augmentation pipelines
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Model architecture
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Module initialization
â”‚   â”‚   â”œâ”€â”€ deformable_detr_backbone.py  # Main ViT model
â”‚   â”‚   â”œâ”€â”€ heads.py              # BBoxHead & ClassHead
â”‚   â”‚   â”œâ”€â”€ loss.py               # Loss functions (Focal + Smooth L1)
â”‚   â”‚   â”œâ”€â”€ neck.py               # FPN (Feature Pyramid Network)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ set_modules/       # Advanced techniques
â”‚   â”‚       â”œâ”€â”€ __init__.py        # Module initialization
â”‚   â”‚       â”œâ”€â”€ hbs.py            # Hierarchical Background Smoothing
â”‚   â”‚       â””â”€â”€ api.py            # Adversarial Perturbation Injection
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                  # Utility functions
â”‚       â”œâ”€â”€ __init__.py            # Module initialization
â”‚       â”œâ”€â”€ masks.py              # Binary mask generation
â”‚       â”œâ”€â”€ dist.py               # Distributed training utilities
â”‚       â”œâ”€â”€ meter.py              # Metric tracking (AverageMeter, ProgressMeter)
â”‚       â””â”€â”€ viz.py                # Visualization functions
â”‚
â”œâ”€â”€ ğŸ“„ train.py                    # Main training script
â””â”€â”€ ğŸ“„ eval.py                     # Main evaluation/inference script
```

## ğŸ—‚ï¸ File Descriptions

### Root Level Files

| File | Purpose |
|------|---------|
| `README.md` | Complete project documentation |
| `requirements.txt` | Python package dependencies |
| `Makefile` | Common development tasks (make train, make eval, etc.) |
| `.gitignore` | Git ignore patterns |
| `LICENSE` | Project license |

### Configuration Files (`configs/`)

| File | Purpose |
|------|---------|
| `default.yaml` | Default training configuration (model, data, optimization settings) |
| `coco_small.yaml` | Template for small COCO dataset configuration |

### Data Directory (`data/`)

| Item | Purpose |
|------|---------|
| `README_DATA.md` | Data format guide and examples |
| `train/` | Training image files |
| `train_annotations.txt` | Training ground truth annotations |
| `val/` | Validation image files |
| `val_annotations.txt` | Validation annotations |
| `test/` | Test image files |
| `test_annotations.txt` | Test annotations |

### Scripts (`scripts/`)

| Script | Purpose |
|--------|---------|
| `setup_coco.sh` | Initial project setup (creates directories, installs deps) |
| `train.sh` | Wrapper script to run training with default settings |
| `eval.sh` | Wrapper script to run evaluation with default settings |

### Source Code (`src/`)

#### Datasets Module (`src/datasets/`)

| File | Class/Function | Purpose |
|------|---|---------|
| `__init__.py` | - | Module exports |
| `transforms.py` | `TinyObjectAugmentation` | Data augmentation pipelines for training/validation/test |
| `coco.py` | `TinyObjectDataset` | Custom dataset class for loading images and annotations |

#### Models Module (`src/models/`)

| File | Class/Function | Purpose |
|------|---|---------|
| `__init__.py` | - | Module exports |
| `deformable_detr_backbone.py` | `TinyObjectViT` | Main Vision Transformer architecture |
| `heads.py` | `BBoxHead`, `ClassHead` | Prediction heads for detection |
| `loss.py` | `TinyObjectLoss` | Combined Focal Loss + Smooth L1 Loss |
| `neck.py` | `FPN` | Feature Pyramid Network (template) |

#### SET Modules (`src/models/set_modules/`)

| File | Class/Function | Purpose |
|------|---|---------|
| `__init__.py` | - | Module exports |
| `hbs.py` | `HierarchicalBackgroundSmoothing` | Background noise reduction technique |
| `api.py` | `AdversarialPerturbationInjection` | Adversarial training for robustness |

#### Utilities Module (`src/utils/`)

| File | Class/Function | Purpose |
|------|---|---------|
| `__init__.py` | - | Module exports |
| `masks.py` | `MaskGenerator` | Generate binary masks for detection |
| `dist.py` | `synchronize()`, `get_rank()`, `get_world_size()` | Distributed training helpers |
| `meter.py` | `AverageMeter`, `ProgressMeter` | Track metrics and training progress |
| `viz.py` | `visualize_detections()`, `plot_training_curves()` | Visualization utilities |

### Main Scripts

| Script | Purpose |
|--------|---------|
| `train.py` | Main training pipeline with Trainer class |
| `eval.py` | Evaluation and inference script with Evaluator class |

## ğŸ”„ Data Flow

### Training Flow
```
data/ â†’ TinyObjectDataset â†’ DataLoader
                â†“
        TinyObjectAugmentation
                â†“
        train.py (Trainer)
                â†“
        TinyObjectViT (model)
                â†“
        TinyObjectLoss (criterion)
                â†“
        Optimizer (AdamW)
                â†“
        checkpoints/best_model.pt
```

### Inference Flow
```
data/ â†’ Image Loading â†’ Augmentation (test transforms)
                â†“
        TinyObjectViT (model)
                â†“
        Detection heads (bbox + class predictions)
                â†“
        Post-processing (confidence filtering)
                â†“
        Detections (boxes, classes, scores)
                â†“
        visualize_detections()
                â†“
        eval_results/
```

## ğŸ“ Key Configuration Files

### `configs/default.yaml`

Controls all training parameters:

```yaml
MODEL:           # Model architecture settings
TRAIN:           # Training hyperparameters
DATA:            # Data loading settings
OPTIMIZER:       # Optimizer configuration
SCHEDULER:       # Learning rate scheduler
CHECKPOINT:      # Model saving
LOGGING:         # Logging configuration
INFERENCE:       # Inference settings
```

### `data/train_annotations.txt` Format

```
image_001.jpg 50 100 75 125 0
image_002.jpg 10 10 30 30 0 200 50 240 90 1
image_003.jpg
```

Format: `filename x1 y1 x2 y2 class [x1 y1 x2 y2 class ...]`

## ğŸš€ Usage Examples

### 1. Setup Project
```bash
bash scripts/setup_coco.sh
```

### 2. Train Model
```bash
python train.py --config configs/default.yaml --epochs 50
```

### 3. Evaluate Model
```bash
python eval.py --config configs/default.yaml --checkpoint checkpoints/best_model.pt
```

### 4. Single Image Inference
```bash
python eval.py --config configs/default.yaml --checkpoint checkpoints/best_model.pt --image test.jpg
```

### 5. Using Makefile
```bash
make install          # Install dependencies
make train            # Train the model
make eval             # Evaluate the model
make clean            # Clean cache
make gpu-info         # Check GPU
```

## ğŸ“¦ Dependencies

See `requirements.txt`:
- torch
- torchvision
- numpy
- pillow
- albumentations
- pyyaml
- opencv-python
- matplotlib
- tqdm

## ğŸ” File Locations Reference

| What | Where |
|------|-------|
| Trained models | `checkpoints/` |
| Evaluation results | `eval_results/` |
| Training logs | `logs/` |
| Configuration | `configs/*.yaml` |
| Training code | `train.py` |
| Evaluation code | `eval.py` |
| Model architecture | `src/models/deformable_detr_backbone.py` |
| Dataset loading | `src/datasets/coco.py` |
| Loss functions | `src/models/loss.py` |
| Augmentation | `src/datasets/transforms.py` |

## ğŸ¯ Next Steps

1. **Setup**: Run `bash scripts/setup_coco.sh`
2. **Prepare Data**: Put images in `data/train`, `data/val`, `data/test`
3. **Create Annotations**: Write annotation files
4. **Configure**: Edit `configs/default.yaml` as needed
5. **Train**: Run `python train.py --config configs/default.yaml`
6. **Evaluate**: Run `python eval.py --config configs/default.yaml --checkpoint checkpoints/best_model.pt`

---

For more details, see `README.md` and individual module documentation.